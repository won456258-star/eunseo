# íŒŒì¼ëª…: create_vector_db.py (API í‚¤ ì‚¬ìš© ë²„ì „)
import os
import sys
from dotenv import load_dotenv
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
print("âœ… .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
load_dotenv()

def create_and_store_db():
    # 1. í…ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ
    print("\nâœ… 'my_data.txt' íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
    loader = TextLoader("my_data.txt", encoding="utf-8")
    documents = loader.load()

    # 2. í…ìŠ¤íŠ¸ ë¶„í• 
    print("\nâœ… ë¬¸ì„œë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    docs = text_splitter.split_documents(documents)

    # 3. OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
    print("\nâœ… OpenAI ì„ë² ë”© ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
    try:
        embeddings = OpenAIEmbeddings()
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: OpenAIEmbeddings ì´ˆê¸°í™” ì‹¤íŒ¨. API í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”. (ìƒì„¸: {e})")
        sys.exit(1)

    # 4. FAISS ë²¡í„° DB ìƒì„± ë° ì €ì¥
    print("\nâœ… FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.")
    try:
        vectorstore = FAISS.from_documents(docs, embeddings)
        vectorstore.save_local("my_faiss_db")
        print("\nğŸ‰ğŸ‰ğŸ‰ ì„±ê³µ! 'my_faiss_db' í´ë”ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: FAISS DB ìƒì„± ì‹¤íŒ¨. API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸í•˜ì„¸ìš”. (ìƒì„¸: {e})")
        sys.exit(1)

if __name__ == '__main__':
    create_and_store_db()